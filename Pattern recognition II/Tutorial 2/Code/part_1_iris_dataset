{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"part_1_iris_dataset","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vHSCJx9DE2--","colab_type":"code","colab":{}},"source":["# Code to mount your Google Drive\n","# Click the play button, then click the link, copy the password and paste it\n","# in the box area.\n","from google.colab import drive \n","\n","drive.mount(\"/content/gdrive\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rR-foa1CLXca","colab_type":"code","colab":{}},"source":["# Set as current directory \"gdrive/My Drive/AGH/Pattern Recognition\" path\n","import os\n","import pandas as pd\n","\n","os.chdir('gdrive/My Drive/AGH/Pattern Recognition')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYTRxewwMfxM","colab_type":"code","colab":{}},"source":["# Import the iris dataset\n","data = pd.read_csv(\"iris.csv\")\n","\n","# Printing the original Dataset\n","data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8DhgJXfPJjA","colab_type":"code","colab":{}},"source":["# Revoming features with low variance\n","# This is the first scikit method which can be found in the link below\n","# https://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance\n","\n","import statistics\n","from sklearn import preprocessing\n","\n","# Selecting only the features from the initial table \n","# We don't need Class\n","features=data.iloc[:,0:4] \n","\n","# Normalizing Data\n","min_max_scaler = preprocessing.MinMaxScaler()\n","features_scaled_in_array = min_max_scaler.fit_transform(features)\n","features_scaled = pd.DataFrame(features_scaled_in_array)\n","\n","# Calculating the variance of each feature\n","var = features_scaled.var(axis=0)\n","\n","# Setting a specific threshold of variance\n","threshold = 0.06\n","\n","# Dropping each feature(column) that has lower variance than our threshold.\n","for i in range(4):\n","  if var[i]<threshold:\n","    features_scaled.drop(columns=[i], axis = 1,inplace = True)\n","# Print selected features\n","\n","features_scaled "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQRd_dYugiaG","colab_type":"code","colab":{}},"source":["# Ordered diagram of the weights\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Make the dataset:\n","list1 = var\n","list2 = (\t'sepal length',\t'sepal width',\t'petal length'\t,'petal width'\t)\n","\n","# Order the lists in reference with the variance\n","list1, list2 = zip(*sorted(zip(list1, list2)))\n","y_pos = np.arange(len(list2))\n","\n","# Create bars\n","plt.bar(y_pos, list1)\n"," \n","# Create names on the x-axis\n","plt.xticks(y_pos, list2)\n"," \n","# Show graphic\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqwjrs9ilEBx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8d9d7cd4-f422-4dfa-d879-77c537c79e0f","executionInfo":{"status":"ok","timestamp":1584802104850,"user_tz":-60,"elapsed":451,"user":{"displayName":"giannis manousaridis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_Qx9DJa3jj5S7eYvV_Q84-WjITVJDDo7Fjt3KAw=s64","userId":"11391910848866561307"}}},"source":["# Univariate feature selection\n","# This is the second scikit method which can be found in the link below\n","# https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\n","\n","\n","from sklearn.datasets import load_iris\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import *\n","\n","# Importing again the iris Dataset, to use the second method for feature selection\n","X, y = load_iris(return_X_y=True)\n","\n","# Normalizing the data\n","X = (preprocessing.normalize(X))\n","\n","# Using the second method to perform feature selection\n","# As a scoring/selection function you could use: chi2, f_classif, mutual_info_classif\n","# k is the number of features to be kept\n","X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n","\n","# Printing Selected Features\n","X_new\n"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.31154917, 3.79497127, 8.19123092, 5.97236278])"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"f-HXaf-rlFty","colab_type":"code","colab":{}},"source":["# Ordered diagram of the weights\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","X_new = SelectKBest(chi2, k=2).fit(X, y)\n","scores = list(X_new.scores_)\n","\n","# Make the dataset:\n","list1 = scores\n","list2 = (\t'sepal length',\t'sepal width',\t'petal length'\t,'petal width'\t)\n","\n","# Order the lists in reference with the variance\n","list1, list2 = zip(*sorted(zip(list1, list2)))\n","y_pos = np.arange(len(list2))\n","\n","# Create bars\n","plt.bar(y_pos, list1)\n"," \n","# Create names on the x-axis\n","plt.xticks(y_pos, list2)\n"," \n","# Show graphic\n","plt.show()"],"execution_count":0,"outputs":[]}]}