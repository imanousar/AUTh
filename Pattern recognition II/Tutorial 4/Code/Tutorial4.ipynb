{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading the training set**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.00000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.037729</td>\n",
       "      <td>0.098371</td>\n",
       "      <td>0.242343</td>\n",
       "      <td>0.402571</td>\n",
       "      <td>0.808757</td>\n",
       "      <td>2.215843</td>\n",
       "      <td>5.649971</td>\n",
       "      <td>...</td>\n",
       "      <td>34.581886</td>\n",
       "      <td>23.268000</td>\n",
       "      <td>16.565943</td>\n",
       "      <td>17.86960</td>\n",
       "      <td>22.821271</td>\n",
       "      <td>17.894157</td>\n",
       "      <td>8.496757</td>\n",
       "      <td>2.723057</td>\n",
       "      <td>0.823229</td>\n",
       "      <td>0.069586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872302</td>\n",
       "      <td>0.088152</td>\n",
       "      <td>0.319931</td>\n",
       "      <td>1.472886</td>\n",
       "      <td>2.419523</td>\n",
       "      <td>4.360495</td>\n",
       "      <td>5.811048</td>\n",
       "      <td>8.269954</td>\n",
       "      <td>14.231137</td>\n",
       "      <td>23.754212</td>\n",
       "      <td>...</td>\n",
       "      <td>57.594114</td>\n",
       "      <td>48.882093</td>\n",
       "      <td>42.005114</td>\n",
       "      <td>43.99069</td>\n",
       "      <td>51.812432</td>\n",
       "      <td>45.146046</td>\n",
       "      <td>29.494913</td>\n",
       "      <td>17.261065</td>\n",
       "      <td>9.110774</td>\n",
       "      <td>2.099525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.00000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean       4.500000      0.000829      0.006743      0.037729      0.098371   \n",
       "std        2.872302      0.088152      0.319931      1.472886      2.419523   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000     16.000000     45.000000    226.000000    185.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.242343      0.402571      0.808757      2.215843      5.649971   \n",
       "std        4.360495      5.811048      8.269954     14.231137     23.754212   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    230.000000    247.000000    255.000000    254.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777     pixel778  \\\n",
       "count  ...  70000.000000  70000.000000  70000.000000  70000.00000   \n",
       "mean   ...     34.581886     23.268000     16.565943     17.86960   \n",
       "std    ...     57.594114     48.882093     42.005114     43.99069   \n",
       "min    ...      0.000000      0.000000      0.000000      0.00000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.00000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.00000   \n",
       "75%    ...     57.000000      8.000000      0.000000      0.00000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.00000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean      22.821271     17.894157      8.496757      2.723057      0.823229   \n",
       "std       51.812432     45.146046     29.494913     17.261065      9.110774   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel784  \n",
       "count  70000.000000  \n",
       "mean       0.069586  \n",
       "std        2.099525  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max      170.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('fmnist.csv')\n",
    "print(train.shape)\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting overlapping classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose from the MNIST set two of the most\n",
    "#overlapping classes (e.g. from MNISTA 3 and 8; or 5.3; 4.9; 9.7).\n",
    "#Create the filter\n",
    "class_1 = 2\n",
    "class_2 = 3\n",
    "train_filter = np.where((train['label'] == class_1) | (train['label'] == class_2))\n",
    "\n",
    "train_filter1 = np.where(train['label'] == class_1)\n",
    "train_filter2 = np.where(train['label'] == class_2)\n",
    "\n",
    "#Apply the filter\n",
    "x_train = train.iloc[train_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class1 = train.iloc[train_filter1]\n",
    "class2 = train.iloc[train_filter2]\n",
    "\n",
    "data = np.matrix(class1)\n",
    "output = data[:, 0]\n",
    "data = np.delete(data, 0, 1)\n",
    "img = data[0].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "data = np.matrix(class2)\n",
    "output = data[:, 0]\n",
    "data = np.delete(data, 0, 1)\n",
    "img = data[0].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dimensionality Reduction**\n",
    "First of all we split the whole dataset in features and class, then we prepare the split of both sets to training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.drop(['label'], axis='columns', inplace=False)\n",
    "y_train = x_train['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X_train, y_train, test_size=0.30, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA, MNIST will be transform to 30-D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.289s\n"
     ]
    }
   ],
   "source": [
    "#PCA\n",
    "n_components = 30\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "X_train_pca = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526302920817581"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pca.explained_variance_ratio_, bins=n_components, log=True)\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 estimators:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.970929\n",
      "\t\tF1      : 0.970929\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.972429\n",
      "\t\tF1      : 0.972429\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.972500\n",
      "\t\tF1      : 0.972500\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 0.971786\n",
      "\t\tF1      : 0.971786\n",
      "\tMean Accuracy: 0.971911\n",
      "\tMean F1      : 0.971911\n",
      "3 estimators:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.971429\n",
      "\t\tF1      : 0.971428\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.972214\n",
      "\t\tF1      : 0.972214\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.972786\n",
      "\t\tF1      : 0.972786\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 0.971857\n",
      "\t\tF1      : 0.971857\n",
      "\tMean Accuracy: 0.972071\n",
      "\tMean F1      : 0.972071\n",
      "4 estimators:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.972857\n",
      "\t\tF1      : 0.972857\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.972214\n",
      "\t\tF1      : 0.972214\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.972071\n",
      "\t\tF1      : 0.972071\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 0.972214\n",
      "\t\tF1      : 0.972214\n",
      "\tMean Accuracy: 0.972339\n",
      "\tMean F1      : 0.972339\n",
      "5 estimators:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.971357\n",
      "\t\tF1      : 0.971357\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.972214\n",
      "\t\tF1      : 0.972214\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.972857\n",
      "\t\tF1      : 0.972857\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 0.972071\n",
      "\t\tF1      : 0.972071\n",
      "\tMean Accuracy: 0.972125\n",
      "\tMean F1      : 0.972125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#This loop show us how the accuracy and F1 changes for the increasing number of classifiers\n",
    "for n in range(2, 6):\n",
    "    print(\"%i estimators:\" % n)\n",
    "    accuracy_sum = 0.0\n",
    "    f1_sum = 0.0\n",
    "    #We use Logistic Regression as the model for the BagginClassifier\n",
    "    for sample_subset in np.arange(0.2, 1.0, 0.2):\n",
    "        #We configure BaggingClassifier to get Bagging Classifier\n",
    "        ensemble = BaggingClassifier(\n",
    "            base_estimator=LogisticRegression(),\n",
    "            n_estimators=n,\n",
    "            max_samples=sample_subset,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        ensemble.fit(X_train_pca, y_train)\n",
    "        pred = ensemble.predict(X_train_pca)\n",
    "        accuracy = metrics.accuracy_score(y_train, pred)\n",
    "        f1 = metrics.f1_score(y_train, pred, average='macro')\n",
    "        accuracy_sum += accuracy\n",
    "        f1_sum += f1\n",
    "        print(\"\\t%3i%% of samples:\" % int(sample_subset*100))\n",
    "        print(\"\\t\\tAccuracy: %f\" % accuracy)\n",
    "        print(\"\\t\\tF1      : %f\" % f1)\n",
    "    print(\"\\tMean Accuracy: %f\" % (accuracy_sum/4))\n",
    "    print(\"\\tMean F1      : %f\" % (f1_sum/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 estimators:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.843929\n",
      "\t\tF1      : 0.843495\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.850143\n",
      "\t\tF1      : 0.849683\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.568571\n",
      "\t\tF1      : 0.568571\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.954571\n",
      "\t\tF1      : 0.954567\n",
      "\tMean Accuracy: 0.804304\n",
      "\tMean F1      : 0.804079\n",
      "3 estimators:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.542500\n",
      "\t\tF1      : 0.542433\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.537357\n",
      "\t\tF1      : 0.537264\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.723643\n",
      "\t\tF1      : 0.722991\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.962643\n",
      "\t\tF1      : 0.962641\n",
      "\tMean Accuracy: 0.691536\n",
      "\tMean F1      : 0.691332\n",
      "4 estimators:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.961214\n",
      "\t\tF1      : 0.961210\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.747429\n",
      "\t\tF1      : 0.746997\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.971571\n",
      "\t\tF1      : 0.971571\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.963000\n",
      "\t\tF1      : 0.962996\n",
      "\tMean Accuracy: 0.910804\n",
      "\tMean F1      : 0.910694\n",
      "5 estimators:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.949143\n",
      "\t\tF1      : 0.949138\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.836000\n",
      "\t\tF1      : 0.835720\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.970143\n",
      "\t\tF1      : 0.970142\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.916000\n",
      "\t\tF1      : 0.915923\n",
      "\tMean Accuracy: 0.917821\n",
      "\tMean F1      : 0.917731\n"
     ]
    }
   ],
   "source": [
    "for n in range(2, 6):\n",
    "    print(\"%i estimators:\" % n)\n",
    "    accuracy_sum = 0.0\n",
    "    f1_sum = 0.0\n",
    "    for feature_subset in np.arange(0.2, 1.0, 0.2):\n",
    "        #Configuration to create RandomForest\n",
    "        ensemble = BaggingClassifier(\n",
    "            base_estimator=LogisticRegression(),\n",
    "            n_estimators=n,\n",
    "            bootstrap=False,\n",
    "            bootstrap_features=True,\n",
    "            max_features=feature_subset,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        ensemble.fit(X_train_pca, y_train)\n",
    "        pred = ensemble.predict(X_train_pca)\n",
    "        accuracy = metrics.accuracy_score(y_train, pred)\n",
    "        f1 = metrics.f1_score(y_train, pred, average='macro')\n",
    "        accuracy_sum += accuracy\n",
    "        f1_sum += f1\n",
    "        print(\"\\t%3i%% of features:\" % int(feature_subset*100))\n",
    "        print(\"\\t\\tAccuracy: %f\" % accuracy)\n",
    "        print(\"\\t\\tF1      : %f\" % f1)\n",
    "    print(\"\\tMean Accuracy: %f\" % (accuracy_sum/4))\n",
    "    print(\"\\tMean F1      : %f\" % (f1_sum/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Patches (Bagging + Random Subspaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20% of samples:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.733500\n",
      "\t\tF1      : 0.733500\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.970000\n",
      "\t\tF1      : 0.970000\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.957643\n",
      "\t\tF1      : 0.957640\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.970357\n",
      "\t\tF1      : 0.970357\n",
      "\tMean Accuracy: 0.907875\n",
      "\tMean F1      : 0.907874\n",
      " 40% of samples:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.728857\n",
      "\t\tF1      : 0.728853\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.952214\n",
      "\t\tF1      : 0.952214\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.919357\n",
      "\t\tF1      : 0.919206\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.942643\n",
      "\t\tF1      : 0.942599\n",
      "\tMean Accuracy: 0.885768\n",
      "\tMean F1      : 0.885718\n",
      " 60% of samples:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.859571\n",
      "\t\tF1      : 0.859333\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.844357\n",
      "\t\tF1      : 0.843932\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.963000\n",
      "\t\tF1      : 0.963000\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.969714\n",
      "\t\tF1      : 0.969714\n",
      "\tMean Accuracy: 0.909161\n",
      "\tMean F1      : 0.908995\n",
      " 80% of samples:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.968429\n",
      "\t\tF1      : 0.968428\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.912857\n",
      "\t\tF1      : 0.912755\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.898857\n",
      "\t\tF1      : 0.898607\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.960643\n",
      "\t\tF1      : 0.960639\n",
      "\tMean Accuracy: 0.935196\n",
      "\tMean F1      : 0.935107\n",
      "100% of samples:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.555429\n",
      "\t\tF1      : 0.555227\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.872071\n",
      "\t\tF1      : 0.871915\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.916786\n",
      "\t\tF1      : 0.916709\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.944714\n",
      "\t\tF1      : 0.944678\n",
      "\tMean Accuracy: 0.822250\n",
      "\tMean F1      : 0.822132\n"
     ]
    }
   ],
   "source": [
    "for sample_subset in np.arange(0.2, 1.2, 0.2):\n",
    "    accuracy_sum = 0.0\n",
    "    f1_sum = 0.0\n",
    "    print(\"%3i%% of samples:\" % int(sample_subset*100))\n",
    "    for feature_subset in np.arange(0.2, 1.0, 0.2):\n",
    "        ensemble = BaggingClassifier(\n",
    "            base_estimator=LogisticRegression(),\n",
    "            n_estimators=5,\n",
    "            bootstrap_features=True,\n",
    "            max_samples=sample_subset,\n",
    "            max_features=feature_subset,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        ensemble.fit(X_train_pca, y_train)\n",
    "        pred = ensemble.predict(X_train_pca)\n",
    "        accuracy = metrics.accuracy_score(y_train, pred)\n",
    "        f1 = metrics.f1_score(y_train, pred, average='macro')\n",
    "        print(\"\\t%3i%% of features:\" % int(feature_subset*100))\n",
    "        print(\"\\t\\tAccuracy: %f\" % accuracy)\n",
    "        print(\"\\t\\tF1      : %f\" % f1)\n",
    "        accuracy_sum += accuracy\n",
    "        f1_sum += f1\n",
    "        \n",
    "    print(\"\\tMean Accuracy: %f\" % (accuracy_sum/4))\n",
    "    print(\"\\tMean F1      : %f\" % (f1_sum/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest - subsets of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 trees:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.980571\n",
      "\t\tF1      : 0.980571\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.989857\n",
      "\t\tF1      : 0.989857\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.995143\n",
      "\t\tF1      : 0.995143\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 0.998429\n",
      "\t\tF1      : 0.998429\n",
      "\tMean Accuracy: 0.991000\n",
      "\tMean F1      : 0.991000\n",
      "60 trees:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.982929\n",
      "\t\tF1      : 0.982928\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.991071\n",
      "\t\tF1      : 0.991071\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.996643\n",
      "\t\tF1      : 0.996643\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 0.999500\n",
      "\t\tF1      : 0.999500\n",
      "\tMean Accuracy: 0.992536\n",
      "\tMean F1      : 0.992536\n",
      "100 trees:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.982500\n",
      "\t\tF1      : 0.982500\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.991214\n",
      "\t\tF1      : 0.991214\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.997500\n",
      "\t\tF1      : 0.997500\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 0.999643\n",
      "\t\tF1      : 0.999643\n",
      "\tMean Accuracy: 0.992714\n",
      "\tMean F1      : 0.992714\n",
      "140 trees:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.982857\n",
      "\t\tF1      : 0.982857\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.991214\n",
      "\t\tF1      : 0.991214\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.997929\n",
      "\t\tF1      : 0.997929\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 0.999929\n",
      "\t\tF1      : 0.999929\n",
      "\tMean Accuracy: 0.992982\n",
      "\tMean F1      : 0.992982\n",
      "180 trees:\n",
      "\t 20% of samples:\n",
      "\t\tAccuracy: 0.982929\n",
      "\t\tF1      : 0.982929\n",
      "\t 40% of samples:\n",
      "\t\tAccuracy: 0.991357\n",
      "\t\tF1      : 0.991357\n",
      "\t 60% of samples:\n",
      "\t\tAccuracy: 0.998286\n",
      "\t\tF1      : 0.998286\n",
      "\t 80% of samples:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\tMean Accuracy: 0.993143\n",
      "\tMean F1      : 0.993143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for n in range(20, 220, 40):\n",
    "    print(\"%i trees:\" % n)\n",
    "    accuracy_sum = 0.0\n",
    "    f1_sum = 0.0\n",
    "    for sample_subset in np.arange(0.2, 1.0, 0.2):\n",
    "        ensemble = RandomForestClassifier(\n",
    "            n_estimators=n,\n",
    "            max_samples=sample_subset,\n",
    "            random_state=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        ensemble.fit(X_train_pca, y_train)\n",
    "        pred = ensemble.predict(X_train_pca)\n",
    "        accuracy = metrics.accuracy_score(y_train, pred)\n",
    "        f1 = metrics.f1_score(y_train, pred, average='macro')\n",
    "        print(\"\\t%3i%% of samples:\" % int(sample_subset*100))\n",
    "        print(\"\\t\\tAccuracy: %f\" % accuracy)\n",
    "        print(\"\\t\\tF1      : %f\" % f1)\n",
    "        accuracy_sum += accuracy\n",
    "        f1_sum += f1\n",
    "        \n",
    "    print(\"\\tMean Accuracy: %f\" % (accuracy_sum/4))\n",
    "    print(\"\\tMean F1      : %f\" % (f1_sum/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest - subsets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 trees:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 0.999214\n",
      "\t\tF1      : 0.999214\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 0.999143\n",
      "\t\tF1      : 0.999143\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.998714\n",
      "\t\tF1      : 0.998714\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.998714\n",
      "\t\tF1      : 0.998714\n",
      "\tMean Accuracy: 0.998946\n",
      "\tMean F1      : 0.998946\n",
      "60 trees:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 0.999857\n",
      "\t\tF1      : 0.999857\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 0.999857\n",
      "\t\tF1      : 0.999857\n",
      "\tMean Accuracy: 0.999929\n",
      "\tMean F1      : 0.999929\n",
      "100 trees:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\tMean Accuracy: 1.000000\n",
      "\tMean F1      : 1.000000\n",
      "140 trees:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\tMean Accuracy: 1.000000\n",
      "\tMean F1      : 1.000000\n",
      "180 trees:\n",
      "\t 20% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 40% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 60% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\t 80% of features:\n",
      "\t\tAccuracy: 1.000000\n",
      "\t\tF1      : 1.000000\n",
      "\tMean Accuracy: 1.000000\n",
      "\tMean F1      : 1.000000\n"
     ]
    }
   ],
   "source": [
    "for n in range(20, 220, 40):\n",
    "    accuracy_sum = 0.0\n",
    "    f1_sum = 0.0\n",
    "    print(\"%i trees:\" % n)\n",
    "    for feature_subset in np.arange(0.2, 1.0, 0.2):\n",
    "        ensemble = RandomForestClassifier(\n",
    "            n_estimators=n,\n",
    "            max_features=feature_subset,\n",
    "            random_state=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        ensemble.fit(X_train_pca, y_train)\n",
    "        pred = ensemble.predict(X_train_pca)\n",
    "        accuracy = metrics.accuracy_score(y_train, pred)\n",
    "        f1 = metrics.f1_score(y_train, pred, average='macro')\n",
    "        print(\"\\t%3i%% of features:\" % int(feature_subset*100))\n",
    "        print(\"\\t\\tAccuracy: %f\" % accuracy)\n",
    "        print(\"\\t\\tF1      : %f\" % f1)\n",
    "        accuracy_sum += accuracy\n",
    "        f1_sum += f1\n",
    "    print(\"\\tMean Accuracy: %f\" % (accuracy_sum/4))\n",
    "    print(\"\\tMean F1      : %f\" % (f1_sum/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 trees:\n",
      "\tAccuracy: 0.967714\n",
      "\tF1      : 0.967714\n",
      "60 trees:\n",
      "\tAccuracy: 0.972500\n",
      "\tF1      : 0.972500\n",
      "100 trees:\n",
      "\tAccuracy: 0.973929\n",
      "\tF1      : 0.973929\n",
      "140 trees:\n",
      "\tAccuracy: 0.976143\n",
      "\tF1      : 0.976143\n",
      "180 trees:\n",
      "\tAccuracy: 0.977500\n",
      "\tF1      : 0.977500\n",
      "\tMean Accuracy: 1.216946\n",
      "\tMean F1      : 1.216946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "accuracy_sum = 0.0\n",
    "f1_sum = 0.0\n",
    "for n in range(20, 220, 40):\n",
    "    \n",
    "    ensemble = AdaBoostClassifier(n_estimators=n, random_state=0)\n",
    "    ensemble.fit(X_train_pca, y_train)\n",
    "    pred = ensemble.predict(X_train_pca)\n",
    "    accuracy = metrics.accuracy_score(y_train, pred)\n",
    "    f1 = metrics.f1_score(y_train, pred, average='macro')\n",
    "    print(\"%i trees:\" % n)\n",
    "    print(\"\\tAccuracy: %f\" % accuracy)\n",
    "    print(\"\\tF1      : %f\" % f1)\n",
    "    accuracy_sum += accuracy\n",
    "    f1_sum += f1\n",
    "print(\"\\tMean Accuracy: %f\" % (accuracy_sum/5))\n",
    "print(\"\\tMean F1      : %f\" % (f1_sum/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean Accuracy: 0.973557\n",
      "\tMean F1      : 0.973557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\tMean Accuracy: %f\" % (accuracy_sum/5))\n",
    "print(\"\\tMean F1      : %f\" % (f1_sum/5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
